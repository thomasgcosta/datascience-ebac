{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Regressão múltipla\n",
    "\n",
    "<br>\n",
    "\n",
    "### Índice <a name=\"topo\"></a>\n",
    "\n",
    "1. [Simulando a distribuição de $\\hat{\\beta}$](#1)\n",
    "\n",
    "\n",
    "2. [Testando hipóteses sobre os parâmetros](#2)\n",
    "\n",
    "\n",
    "3. [Variáveis Qualitativas](#3)\n",
    "\n",
    "\n",
    "4. [Qualidade do modelo](#4)\n",
    "    - $R^2$\n",
    "    - AIC\n",
    "    - $R^2_{ajustado}$\n",
    "\n",
    "5. [Seleção de variáveis](#5)\n",
    "    - forward\n",
    "    - backward\n",
    "    - stepwise  \n",
    "\n",
    "6. [Regularização](#6)\n",
    "    - L1 lasso\n",
    "    - L2 ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import metrics\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# from scipy.stats import ks_2samp\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import patsy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simulando a distribuição de $\\hat{\\beta}$</span><a name=\"1\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Vamos 50 observações X e y, com uma associação pré-determinada, seguindo a seguinte equação:\n",
    "\n",
    "$y = 5 + 0.1 x + \\epsilon$\n",
    "\n",
    "com o parâmetro aleatório de erro sendo: $\\epsilon \\thicksim N(0,0.5)$\n",
    "\n",
    "Usando a biblioteca ```random``` do numpy é bem fácil simular estes dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x         y\n",
      "x  1.000000  0.079342\n",
      "y  0.079342  1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.3041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 11 Sep 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.584</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:08:38</td>     <th>  Log-Likelihood:    </th> <td> -25.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   55.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   59.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    5.3399</td> <td>    0.115</td> <td>   46.507</td> <td> 0.000</td> <td>    5.109</td> <td>    5.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.0136</td> <td>    0.025</td> <td>    0.551</td> <td> 0.584</td> <td>   -0.036</td> <td>    0.063</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.013</td> <th>  Durbin-Watson:     </th> <td>   2.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.603</td> <th>  Jarque-Bera (JB):  </th> <td>   0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.142</td> <th>  Prob(JB):          </th> <td>   0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.321</td> <th>  Cond. No.          </th> <td>    9.47</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.006   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &    -0.014   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &    0.3041   \\\\\n",
       "\\textbf{Date:}             & Mon, 11 Sep 2023 & \\textbf{  Prob (F-statistic):} &    0.584    \\\\\n",
       "\\textbf{Time:}             &     15:08:38     & \\textbf{  Log-Likelihood:    } &   -25.596   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     55.19   \\\\\n",
       "\\textbf{Df Residuals:}     &          48      & \\textbf{  BIC:               } &     59.02   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       5.3399  &        0.115     &    46.507  &         0.000        &        5.109    &        5.571     \\\\\n",
       "\\textbf{x}         &       0.0136  &        0.025     &     0.551  &         0.584        &       -0.036    &        0.063     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.013 & \\textbf{  Durbin-Watson:     } &    2.269  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.603 & \\textbf{  Jarque-Bera (JB):  } &    0.383  \\\\\n",
       "\\textbf{Skew:}          &  0.142 & \\textbf{  Prob(JB):          } &    0.826  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.321 & \\textbf{  Cond. No.          } &     9.47  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.006\n",
       "Model:                            OLS   Adj. R-squared:                 -0.014\n",
       "Method:                 Least Squares   F-statistic:                    0.3041\n",
       "Date:                Mon, 11 Sep 2023   Prob (F-statistic):              0.584\n",
       "Time:                        15:08:38   Log-Likelihood:                -25.596\n",
       "No. Observations:                  50   AIC:                             55.19\n",
       "Df Residuals:                      48   BIC:                             59.02\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      5.3399      0.115     46.507      0.000       5.109       5.571\n",
       "x              0.0136      0.025      0.551      0.584      -0.036       0.063\n",
       "==============================================================================\n",
       "Omnibus:                        1.013   Durbin-Watson:                   2.269\n",
       "Prob(Omnibus):                  0.603   Jarque-Bera (JB):                0.383\n",
       "Skew:                           0.142   Prob(JB):                        0.826\n",
       "Kurtosis:                       3.321   Cond. No.                         9.47\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('figure', figsize=(6, 4))\n",
    "\n",
    "N = 50\n",
    "\n",
    "\n",
    "x = np.linspace(0,8,N)\n",
    "y = 5 + .1*x + np.random.randn(N)*.5\n",
    "\n",
    "df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "_ = sns.regplot(x='x', y='y', data = df1, ax = ax)\n",
    "ax.set_xlim(0, 8)\n",
    "ax.set_ylim(3, 8)\n",
    "ticks = ax.set_xticks(list(range(0,9,1)))\n",
    "ticks = ax.set_yticks(list(range(3,9,1)))\n",
    "\n",
    "print(df1.corr())\n",
    "\n",
    "reg = smf.ols('y ~ x', data = df1).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variações aleatórias\n",
    "\n",
    "Nessa situação, podemos considerar que estamos extraindo 50 observações das variáveis x e y de forma aleatória de uma população com as característias especificadas.\n",
    "\n",
    "Observe que a cada vez que rodamos a célula acima, obtemos um valor distinto de $\\beta$.\n",
    "\n",
    "Vamos fazer isso algumas vezes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "for i in range(2000):\n",
    "    x = np.linspace(0,8,N)\n",
    "    y = .1*x + np.random.randn(N)*.5\n",
    "    df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "    reg = smf.ols('y ~ x', data = df1).fit()\n",
    "    betas.append(reg.params[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21e642f5450>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 808.75x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('figure', figsize=(20, 10))\n",
    "g = sns.displot([betas], binwidth = .005, height = 5, aspect = 1.5)\n",
    "g.set(xlim=(0, 0.2), ylim=(0, 170))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os valores de $\\beta$ estão em torno do verdadeiro valor (0,1), embora sejam aleatórios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulando sob $H_0$\n",
    "A célula abaixo simula os dados com $\\beta = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "for i in range(2000):\n",
    "    x = np.linspace(0,8,N)\n",
    "    y = 0*x + np.random.randn(N)*.5\n",
    "    df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "    reg = smf.ols('y ~ x', data = df1).fit()\n",
    "    betas.append(reg.params[1])\n",
    "    \n",
    "plt.rc('figure', figsize=(20, 10))\n",
    "g = sns.displot([betas], binwidth = .005, height = 5, aspect = 1.5)\n",
    "g.set(xlim=(-0.15, 0.15), ylim=(0, 170))\n",
    "\n",
    "# sns.displot(betas, binwidth = .005, height = 5, aspect = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que os valores obtidos dos $\\beta$s se concentram em torno do 0,1, e a frequência diminui quanto mais nos afastamos do valor verdadeiro. Essa distribuição tem a \"cara\" de uma distribuição muito conhecida e presente em diversas situações, a distribuição Normal (ou Gaussiana). E sim, sob determinadas circunstâncias, a distribuição do $\\beta$ é de fato Normal e com um desvio padrão conhecido. O desvio padrão de um parâmetro em geral é chamado por outro nome **erro padrão**, e é ele que aparece na saída do statsmodels com o nome de ``` std err ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testando hipóteses sobre os parâmetros</span><a name=\"2\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Queremos saber se uma variável é relevante. Em geral, transformamos as nossas hipóteses para uma afirmação falseável, e sob a qual conseguimos calcular probabilidades. Dessa forma, podemos formular a seguinte hipótese:\n",
    "\n",
    "$H_0: \\beta = 0$  \n",
    "$H_a: \\beta \\neq 0$\n",
    "\n",
    "Assim, sob $H_0$ temos que $\\hat{\\beta}$ dividido pela estimativa do seu erro padrão (*std err*) tem uma distribuição *t-Student* (que é bem parecida com a normal) centrada em zero. **Esse valor corresponde à coluna ```t```** na saída do statsmodels.    \n",
    "\n",
    "Em termos práticos significa que se $\\beta$ está muito longe do zero (comparado com o seu erro padrão), rejeitamos $H_0$, ou seja, se $H_0$ é falsa, significa que $H_a$ é verdadeira, ou seja, $\\beta$ é diferente de zero, o que significa que a variável é relevante no modelo de regressão. \n",
    "\n",
    "Caso contrário, não consideramos a variável relevante no modelo e ela pode ser retirada do modelo.\n",
    "\n",
    "Se você observou um valor $\\hat{\\beta}_{obs}$ como estimativa do seu beta, uma quantidade muito útil de se calcular é $p(|\\hat{\\beta}|>\\hat{\\beta}_{obs})$\n",
    "\n",
    "Um valor interessante na saída do statsmodels é o ```p>|t|```. Vamos lá: \n",
    "\n",
    "- **$\\hat{\\beta}$ é variável aleatória** ok? Primeiro entenda isso. Ele é uma função dos dados. Como os dados são variáveis aleatórias, qualquer função deles é variável aleatória também. Então ele é variável aleatória.\n",
    "- O **p-value** é a probabilidade de obtermos um $\\hat{\\beta}$ mais extremo (maior em valores absolutos) que o observado na nossa amostra, sob $H_0$.\n",
    "- **Regra prática**: então se o *p-value* é muito pequeno, digamos menor que $(1-\\gamma)$, **rejeitamos $H_0$** pois é muito pouco provável observar um beta como estes que observamos sob $H_0$ (Lembra... $H_0$ indica que $\\beta=0$ e a variável é irrelevante no modelo). Esse $\\gamma$ é o que chamamos de confiança e o $(1-\\gamma)$ de significância. Este é o famoso teste de significância aplicado à regressão.\n",
    "- **Regra de bolso**: muitas pessoas usam 5\\% como referência para o *p-value*, outras usam 1\\%. Esse assunto realmente dá pano pra manga e não vamos entrar na polêmica aqui. Mas em todo caso, lembre-se da frase do Box, de que \"todo modelo está errado\" inclusive o seu (e o meu também). A pergunta é o que torna ele útil? E o *p-value* é sem dúvida um valor muito útil.\n",
    "\n",
    "Vamos ver novamente isso no statsmodels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "\n",
    "\n",
    "x = np.linspace(0,8,N)\n",
    "y = 5 + .1*x + np.random.randn(N)*.5\n",
    "\n",
    "df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "\n",
    "_ = sns.regplot(x='x', y='y', data = df1)\n",
    "print(df1.corr())\n",
    "\n",
    "reg = smf.ols('y ~ x', data = df1).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos simular um caso em que $H_0$ é verdadeira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = []\n",
    "for i in range(2000):\n",
    "    x = np.linspace(0,8,N)\n",
    "    y = 0*x + np.random.randn(N)*.5\n",
    "    df1 = pd.DataFrame({'x':x, 'y':y})\n",
    "    reg = smf.ols('y ~ x', data = df1).fit()\n",
    "    betas.append(reg.params[1])\n",
    "    \n",
    "sns.displot(betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observação sobre o teste de significância\n",
    "Repare que os valores simulados de $\\beta$ se distribuem ao longo do verdadeiro valor, que é o zero neste caso, e chegam bem próximoes de 0.1 e -0.1. Se fazemos o nosso teste com 5% de significância, quer dizer que 5% das vezes (1 em cada 20) $H_0$ vai ser verdadeira, mas vamos ter a conclusão errada. Esse é o famoso **erro tipo I** dos testes de hipóteses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variáveis qualitativas </span><a name=\"3\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Já vimos que para tratar variáveis qualitativas precisamos transformá-las em *dummies*, processo este conhecido como *\"hot encoding\"* ou simplesmente *\"encoding\"*.\n",
    "\n",
    "Antes de partir para o próximo tema, vamos mergulhar um pouco mais fundo no entendimento das variáveis *dummy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_pct</th>\n",
       "      <th>net_bill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.063204</td>\n",
       "      <td>15.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.191244</td>\n",
       "      <td>8.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "      <td>0.199886</td>\n",
       "      <td>17.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "      <td>0.162494</td>\n",
       "      <td>20.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "      <td>0.172069</td>\n",
       "      <td>20.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size   tip_pct  net_bill\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2  0.063204     15.98\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3  0.191244      8.68\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3  0.199886     17.51\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2  0.162494     20.37\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4  0.172069     20.98"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "tips['tip_pct'] = tips['tip'] / (tips['total_bill'] - tips['tip'])\n",
    "tips['net_bill'] = tips['total_bill'] - tips['tip']\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='size', ylabel='tip'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(y = 'tip', x = 'size', data = tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (244, 6)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'C(size)[T.2]',\n",
       "     'C(size)[T.3]',\n",
       "     'C(size)[T.4]',\n",
       "     'C(size)[T.5]',\n",
       "     'C(size)[T.6]']\n",
       "  Terms:\n",
       "    'Intercept' (column 0), 'C(size)' (columns 1:6)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x = patsy.dmatrices('tip ~ C(size)', data = tips)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size\n",
       "0     1\n",
       "1     2\n",
       "2     3\n",
       "3     5\n",
       "4     4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'size': [1, 2, 3, 5, 4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (5, 5)\n",
       "  Intercept  C(size)[T.2]  C(size)[T.3]  C(size)[T.4]  C(size)[T.5]\n",
       "          1             0             0             0             0\n",
       "          1             1             0             0             0\n",
       "          1             0             1             0             0\n",
       "          1             0             0             0             1\n",
       "          1             0             0             1             0\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'C(size)' (columns 1:5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import dmatrix\n",
    "dmatrix(\"C(size)\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (244, 6)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'C(size)[T.2]',\n",
       "     'C(size)[T.3]',\n",
       "     'C(size)[T.4]',\n",
       "     'C(size)[T.5]',\n",
       "     'C(size)[T.6]']\n",
       "  Terms:\n",
       "    'Intercept' (column 0), 'C(size)' (columns 1:6)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x = patsy.dmatrices('tip ~ C(size)', data = tips)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>2.17e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:23:36</td>     <th>  Log-Likelihood:    </th> <td> -390.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   792.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   238</td>      <th>  BIC:               </th> <td>   813.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    1.4375</td> <td>    0.606</td> <td>    2.372</td> <td> 0.018</td> <td>    0.244</td> <td>    2.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.2]</th> <td>    1.1448</td> <td>    0.614</td> <td>    1.865</td> <td> 0.063</td> <td>   -0.064</td> <td>    2.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.3]</th> <td>    1.9557</td> <td>    0.637</td> <td>    3.070</td> <td> 0.002</td> <td>    0.701</td> <td>    3.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.4]</th> <td>    2.6979</td> <td>    0.638</td> <td>    4.229</td> <td> 0.000</td> <td>    1.441</td> <td>    3.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.5]</th> <td>    2.5905</td> <td>    0.813</td> <td>    3.186</td> <td> 0.002</td> <td>    0.989</td> <td>    4.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.6]</th> <td>    3.7875</td> <td>    0.857</td> <td>    4.420</td> <td> 0.000</td> <td>    2.099</td> <td>    5.476</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>77.409</td> <th>  Durbin-Watson:     </th> <td>   1.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 244.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.344</td> <th>  Prob(JB):          </th> <td>6.87e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.106</td> <th>  Cond. No.          </th> <td>    24.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    tip   R-squared:                       0.249\n",
       "Model:                            OLS   Adj. R-squared:                  0.233\n",
       "Method:                 Least Squares   F-statistic:                     15.75\n",
       "Date:                Wed, 18 Aug 2021   Prob (F-statistic):           2.17e-13\n",
       "Time:                        11:23:36   Log-Likelihood:                -390.09\n",
       "No. Observations:                 244   AIC:                             792.2\n",
       "Df Residuals:                     238   BIC:                             813.2\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        1.4375      0.606      2.372      0.018       0.244       2.631\n",
       "C(size)[T.2]     1.1448      0.614      1.865      0.063      -0.064       2.354\n",
       "C(size)[T.3]     1.9557      0.637      3.070      0.002       0.701       3.211\n",
       "C(size)[T.4]     2.6979      0.638      4.229      0.000       1.441       3.955\n",
       "C(size)[T.5]     2.5905      0.813      3.186      0.002       0.989       4.192\n",
       "C(size)[T.6]     3.7875      0.857      4.420      0.000       2.099       5.476\n",
       "==============================================================================\n",
       "Omnibus:                       77.409   Durbin-Watson:                   1.807\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              244.825\n",
       "Skew:                           1.344   Prob(JB):                     6.87e-54\n",
       "Kurtosis:                       7.106   Cond. No.                         24.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(y, x).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5823"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.4375 + 1.1448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (244, 6)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'C(size, Treatment(2))[T.1]',\n",
       "     'C(size, Treatment(2))[T.3]',\n",
       "     'C(size, Treatment(2))[T.4]',\n",
       "     'C(size, Treatment(2))[T.5]',\n",
       "     'C(size, Treatment(2))[T.6]']\n",
       "  Terms:\n",
       "    'Intercept' (column 0), 'C(size, Treatment(2))' (columns 1:6)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x = patsy.dmatrices('tip ~ C(size, Treatment(2))', data = tips)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>2.17e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:27:59</td>     <th>  Log-Likelihood:    </th> <td> -390.09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   792.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   238</td>      <th>  BIC:               </th> <td>   813.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>    2.5823</td> <td>    0.097</td> <td>   26.613</td> <td> 0.000</td> <td>    2.391</td> <td>    2.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.1]</th> <td>   -1.1448</td> <td>    0.614</td> <td>   -1.865</td> <td> 0.063</td> <td>   -2.354</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.3]</th> <td>    0.8109</td> <td>    0.219</td> <td>    3.698</td> <td> 0.000</td> <td>    0.379</td> <td>    1.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.4]</th> <td>    1.5531</td> <td>    0.222</td> <td>    7.008</td> <td> 0.000</td> <td>    1.117</td> <td>    1.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.5]</th> <td>    1.4457</td> <td>    0.551</td> <td>    2.626</td> <td> 0.009</td> <td>    0.361</td> <td>    2.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.6]</th> <td>    2.6427</td> <td>    0.614</td> <td>    4.306</td> <td> 0.000</td> <td>    1.434</td> <td>    3.852</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>77.409</td> <th>  Durbin-Watson:     </th> <td>   1.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 244.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.344</td> <th>  Prob(JB):          </th> <td>6.87e-54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.106</td> <th>  Cond. No.          </th> <td>    8.26</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    tip   R-squared:                       0.249\n",
       "Model:                            OLS   Adj. R-squared:                  0.233\n",
       "Method:                 Least Squares   F-statistic:                     15.75\n",
       "Date:                Wed, 18 Aug 2021   Prob (F-statistic):           2.17e-13\n",
       "Time:                        11:27:59   Log-Likelihood:                -390.09\n",
       "No. Observations:                 244   AIC:                             792.2\n",
       "Df Residuals:                     238   BIC:                             813.2\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                      2.5823      0.097     26.613      0.000       2.391       2.773\n",
       "C(size, Treatment(2))[T.1]    -1.1448      0.614     -1.865      0.063      -2.354       0.064\n",
       "C(size, Treatment(2))[T.3]     0.8109      0.219      3.698      0.000       0.379       1.243\n",
       "C(size, Treatment(2))[T.4]     1.5531      0.222      7.008      0.000       1.117       1.990\n",
       "C(size, Treatment(2))[T.5]     1.4457      0.551      2.626      0.009       0.361       2.530\n",
       "C(size, Treatment(2))[T.6]     2.6427      0.614      4.306      0.000       1.434       3.852\n",
       "==============================================================================\n",
       "Omnibus:                       77.409   Durbin-Watson:                   1.807\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              244.825\n",
       "Skew:                           1.344   Prob(JB):                     6.87e-54\n",
       "Kurtosis:                       7.106   Cond. No.                         8.26\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(y, x).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Qualidade do modelo e complexidade</span><a name=\"4\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Quando fazemos uma regressão múltipla, pelo próprio método de mínimos quadrados ordinários, a métrica $R^2$ vai ser necessariamente melhor sempre que adicionarmos uma variável a mais. Sempre. Por menos sentido que a variável faça, por menos informação que ela agregue, o $R^2$ vai ser maior (ou no pior extremo caso, igual) ao que tínhamos antes.\n",
    "\n",
    "Vamos ver isso na prática na base de gorjetas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   21.03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>9.61e-20</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:31:49</td>     <th>  Log-Likelihood:    </th> <td> -372.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   759.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   237</td>      <th>  BIC:               </th> <td>   784.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   -0.3279</td> <td>    0.494</td> <td>   -0.664</td> <td> 0.508</td> <td>   -1.301</td> <td>    0.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.1]</th> <td>   -0.1059</td> <td>    0.599</td> <td>   -0.177</td> <td> 0.860</td> <td>   -1.285</td> <td>    1.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.3]</th> <td>    0.4012</td> <td>    0.216</td> <td>    1.859</td> <td> 0.064</td> <td>   -0.024</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.4]</th> <td>    0.8693</td> <td>    0.236</td> <td>    3.679</td> <td> 0.000</td> <td>    0.404</td> <td>    1.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.5]</th> <td>    0.6797</td> <td>    0.530</td> <td>    1.283</td> <td> 0.201</td> <td>   -0.364</td> <td>    1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.6]</th> <td>    1.7283</td> <td>    0.593</td> <td>    2.914</td> <td> 0.004</td> <td>    0.560</td> <td>    2.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(net_bill)</th>           <td>    1.1401</td> <td>    0.190</td> <td>    5.993</td> <td> 0.000</td> <td>    0.765</td> <td>    1.515</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>74.766</td> <th>  Durbin-Watson:     </th> <td>   1.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 231.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.303</td> <th>  Prob(JB):          </th> <td>5.05e-51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.999</td> <th>  Cond. No.          </th> <td>    28.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    tip   R-squared:                       0.347\n",
       "Model:                            OLS   Adj. R-squared:                  0.331\n",
       "Method:                 Least Squares   F-statistic:                     21.03\n",
       "Date:                Wed, 18 Aug 2021   Prob (F-statistic):           9.61e-20\n",
       "Time:                        12:31:49   Log-Likelihood:                -372.87\n",
       "No. Observations:                 244   AIC:                             759.7\n",
       "Df Residuals:                     237   BIC:                             784.2\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     -0.3279      0.494     -0.664      0.508      -1.301       0.645\n",
       "C(size, Treatment(2))[T.1]    -0.1059      0.599     -0.177      0.860      -1.285       1.074\n",
       "C(size, Treatment(2))[T.3]     0.4012      0.216      1.859      0.064      -0.024       0.826\n",
       "C(size, Treatment(2))[T.4]     0.8693      0.236      3.679      0.000       0.404       1.335\n",
       "C(size, Treatment(2))[T.5]     0.6797      0.530      1.283      0.201      -0.364       1.724\n",
       "C(size, Treatment(2))[T.6]     1.7283      0.593      2.914      0.004       0.560       2.897\n",
       "np.log(net_bill)               1.1401      0.190      5.993      0.000       0.765       1.515\n",
       "==============================================================================\n",
       "Omnibus:                       74.766   Durbin-Watson:                   1.966\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              231.626\n",
       "Skew:                           1.303   Prob(JB):                     5.05e-51\n",
       "Kurtosis:                       6.999   Cond. No.                         28.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = smf.ols('tip ~ C(size, Treatment(2)) + np.log(net_bill)', data = tips).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos inserir a variavel *day* e checar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>6.16e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:33:41</td>     <th>  Log-Likelihood:    </th> <td> -372.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   234</td>      <th>  BIC:               </th> <td>   800.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   -0.3904</td> <td>    0.504</td> <td>   -0.775</td> <td> 0.439</td> <td>   -1.383</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.1]</th> <td>   -0.1007</td> <td>    0.605</td> <td>   -0.166</td> <td> 0.868</td> <td>   -1.293</td> <td>    1.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.3]</th> <td>    0.3880</td> <td>    0.221</td> <td>    1.757</td> <td> 0.080</td> <td>   -0.047</td> <td>    0.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.4]</th> <td>    0.8480</td> <td>    0.242</td> <td>    3.510</td> <td> 0.001</td> <td>    0.372</td> <td>    1.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.5]</th> <td>    0.6527</td> <td>    0.536</td> <td>    1.217</td> <td> 0.225</td> <td>   -0.404</td> <td>    1.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size, Treatment(2))[T.6]</th> <td>    1.7578</td> <td>    0.604</td> <td>    2.911</td> <td> 0.004</td> <td>    0.568</td> <td>    2.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day[T.Fri]</th>                 <td>    0.1562</td> <td>    0.301</td> <td>    0.520</td> <td> 0.604</td> <td>   -0.436</td> <td>    0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day[T.Sat]</th>                 <td>    0.0385</td> <td>    0.195</td> <td>    0.197</td> <td> 0.844</td> <td>   -0.346</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day[T.Sun]</th>                 <td>    0.1393</td> <td>    0.202</td> <td>    0.689</td> <td> 0.491</td> <td>   -0.259</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(net_bill)</th>           <td>    1.1395</td> <td>    0.192</td> <td>    5.931</td> <td> 0.000</td> <td>    0.761</td> <td>    1.518</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>75.986</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 240.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.318</td> <th>  Prob(JB):          </th> <td>7.65e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.082</td> <th>  Cond. No.          </th> <td>    28.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    tip   R-squared:                       0.349\n",
       "Model:                            OLS   Adj. R-squared:                  0.324\n",
       "Method:                 Least Squares   F-statistic:                     13.96\n",
       "Date:                Wed, 18 Aug 2021   Prob (F-statistic):           6.16e-18\n",
       "Time:                        12:33:41   Log-Likelihood:                -372.52\n",
       "No. Observations:                 244   AIC:                             765.0\n",
       "Df Residuals:                     234   BIC:                             800.0\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     -0.3904      0.504     -0.775      0.439      -1.383       0.602\n",
       "C(size, Treatment(2))[T.1]    -0.1007      0.605     -0.166      0.868      -1.293       1.092\n",
       "C(size, Treatment(2))[T.3]     0.3880      0.221      1.757      0.080      -0.047       0.823\n",
       "C(size, Treatment(2))[T.4]     0.8480      0.242      3.510      0.001       0.372       1.324\n",
       "C(size, Treatment(2))[T.5]     0.6527      0.536      1.217      0.225      -0.404       1.709\n",
       "C(size, Treatment(2))[T.6]     1.7578      0.604      2.911      0.004       0.568       2.947\n",
       "day[T.Fri]                     0.1562      0.301      0.520      0.604      -0.436       0.749\n",
       "day[T.Sat]                     0.0385      0.195      0.197      0.844      -0.346       0.423\n",
       "day[T.Sun]                     0.1393      0.202      0.689      0.491      -0.259       0.537\n",
       "np.log(net_bill)               1.1395      0.192      5.931      0.000       0.761       1.518\n",
       "==============================================================================\n",
       "Omnibus:                       75.986   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              240.004\n",
       "Skew:                           1.318   Prob(JB):                     7.65e-53\n",
       "Kurtosis:                       7.082   Cond. No.                         28.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = smf.ols('tip ~ C(size, Treatment(2)) + np.log(net_bill) + day', data = tips).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observações\n",
    "\n",
    "- O $R^2$ aumentou, embora a variável adicionada não pareça ser significante.\n",
    "- O $R^2$ sempre vai aumentar. Na pior das hipóteses ele fica igual.\n",
    "- O modelo ficou mais \"complicado\".\n",
    "- Estamos aumentando o risco de \"overfitting\".\n",
    "- Esta variável adicional interfere nas estimativas dos demais parâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navalha de Occam\n",
    "\n",
    "Um princípio conhecido como *[Navalha de Occam](https://en.wikipedia.org/wiki/Occam%27s_razor)* indica que se temos dois modelos com indicadores iguais de qualidade, e um é mais simples, o mais simples é desejável. Dessa forma, diversas propostas surgem na tentativa de \"balisar\" a quantidade de parâmetros no modelo, como o $R^2$-*ajustado* - que sofre uma penalização por cada parâmetro no modelo e o AIC que vamos discutir adiante.\n",
    "\n",
    "Com isso em mente, há na literatura diversas alternativas para se considerar a complexidade do modelo na medida de qualidade, como o critério de Akaike (AIC) e o $R^2-ajustado$.\n",
    "\n",
    "#### AIC\n",
    "\n",
    "*Akaike´s Information Criterion* (ou critério da informação de Akaike). É uma métrica mais \"estatística\" de qualidade de ajuste do modelo, desenhada para comparar modelos com diferentes combinações de variáveis. Quanto menor o AIC, melhor o modelo - ou seja, se colocamos uma nova variável no modelo, por esse critério ela é relevante se o AIC diminuir, e não é relevante caso contrário. \n",
    "\n",
    "Diferente do $R^2$, o AIC depende do tamanho da amostra, de modo que não tem uma 'regra de bolso' do tipo \"perto de 1 é bom\", mas é adequado para comparar modelos na mesma amostra.\n",
    "\n",
    "A Wikipedia tem um artigo interessante sobre o [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion).\n",
    "\n",
    "#### $R^2-ajustado$\n",
    "\n",
    "O $R^2$-ajustado procura ponderar o incremento em explicação da variabilidade com o incremento em complexidade do modelo em termos de número de parâmetros. Ele aumenta se o $R^2$ aumentar mais do que o esperado \"por acaso\", e diminui caso contrário. Sua fórmula é a seguinte:\n",
    "\n",
    "$$R^2_{aj} = 1- \\left[ \\frac{(1-R^2)(n-1)}{(n-k-1)} \\right]$$\n",
    "\n",
    "#### Observações do exemplo anterior\n",
    "Repare que, no exercício anterior, quando inserimos uma variável irrelevante no modelo, o $R^2$ aumentou, mas o $R^2-ajustado$ diminuiu e o AIC aumentou, sugerindo que esta variável não deve entrar no modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Seleção de modelos </span><a name=\"5\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Três algoritmos clássicos na literatura estatística para seleção de variáveis:\n",
    "\n",
    "- *Forward*:  \n",
    "    Parte de um modelo vazio e vai incluindo variáveis estatisticamente relevantes uma a uma, priorizando a mais relevante, até que nenhuma seja incluída. Pode haver alguma variável que deixou de ser relevante na presença daquelas que foram incluídas depois.\n",
    "    1. Definir um limite *LI* de *p-value* para uma variável ser **incluída** no modelo\n",
    "    2. Iniciar com um modelo sem variáveis\n",
    "    3. Para cada variável fora do modelo, testar $\\beta = 0$ na presença das demais - armazenar o *p-value*\n",
    "    4. Se o menor *p-value* for menor que *L*, a variável correspondente é incluída no modelo\n",
    "    5. Repetir 3 e 4 até que não sejam adicionadas variáveis ao modelo\n",
    "    <br><br>\n",
    "- *Backward*:  \n",
    "    Parte de um modelo com todas as variáveis possíveis consideradas e vai removendo-as uma a uma, até que nenhuma seja removida. Pode haver variáveis relevantes ainda após o término.\n",
    "    1. Definir um limite *LE* de *p-value* para uma variável ser **excluída** do modelo\n",
    "    2. Para cada variável incluída no modelo, testar $\\beta = 0$ na presença das demais - armazenar o *p-value*\n",
    "    3. Se o menor *p-value* for maior que *LE*, a variável é excluída do modelo\n",
    "    5. Repetir 3 e 4 até que não sejam excluídas mais variáveis do modelo\n",
    "- *Stepwise*:\n",
    "    É básicamente uma mistura dos dois. Vai incluindo variáveis, eventualmente removendo alguma variável caso seja irrelevante na presença das demais.\n",
    "    \n",
    "**Crítica**: Essa abordagem é criticada na comunidade porque esse *p-value* é tido mais como uma referência. Muitos usam esse algoritmo com o critério de Akaike ao invés do *p-value*, ou mesmo as regularizações L1 e L2, com a qual é possível fazer um *grid search* para buscar melhores resultados em previsão.\n",
    "\n",
    "De qualquer forma, a seleção de um modelo por um desses algoritmos **muito raramente** (pra não dizer nunca) é a escolha final. Sempre há insights e ajustes a serem feitos, categorias a agrupar, variáveis conceitualmente importantes que podem ser priorizadas, multicolinearidade a ser tratada (mais sobre isso adiante), enfim, é um processo meio arte meio ciência suportado por algoritmos menos que executado por algoritmos.\n",
    "\n",
    "O código abaixo foi extraído e adaptado do fórum [*stackovervlow*](https://datascience.stackexchange.com/questions/937/does-scikit-learn-have-a-forward-selection-stepwise-regression-algorithm), da resposta do David Dale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  LSTAT                          with p-value 5.0811e-88\n",
      "#############\n",
      "['LSTAT']\n",
      "Add  RM                             with p-value 3.47226e-27\n",
      "#############\n",
      "['LSTAT', 'RM']\n",
      "Add  PTRATIO                        with p-value 1.64466e-14\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO']\n",
      "Add  DIS                            with p-value 1.66847e-05\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS']\n",
      "Add  NOX                            with p-value 5.48815e-08\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX']\n",
      "Add  CHAS                           with p-value 0.000265473\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS']\n",
      "Add  B                              with p-value 0.000771946\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B']\n",
      "Add  ZN                             with p-value 0.00465162\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN']\n",
      "Add  CRIM                           with p-value 0.0445675\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN', 'CRIM']\n",
      "Add  RAD                            with p-value 0.00169218\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN', 'CRIM', 'RAD']\n",
      "Add  TAX                            with p-value 0.000521424\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN', 'CRIM', 'RAD', 'TAX']\n",
      "#############\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN', 'CRIM', 'RAD', 'TAX']\n",
      "resulting features:\n",
      "['LSTAT', 'RM', 'PTRATIO', 'DIS', 'NOX', 'CHAS', 'B', 'ZN', 'CRIM', 'RAD', 'TAX']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.05, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=np.dtype('float64'))\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.index[new_pval.argmin()]\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                 print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        print(\"#############\")\n",
    "        print(included)\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "variaveis = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(variaveis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Regularização </span><a name=\"6\"></a>\n",
    "[Voltar ao índice](#topo)\n",
    "\n",
    "Regularização (ou *model regularization*) é uma forma de considerar a complexidade adicionada ao modelo e simplificar o modelo, quer seja por deixar os parâmetros menos relevantes, quer seja por retirá-los intrgralmente do modelo.\n",
    "\n",
    "As duas formas mais populares na literatura do aprendizado de máquina são a regularização L1 e a regularização L2:\n",
    "\n",
    "#### Função de perda\n",
    "Vamos relembrar que a nossa regressão é uma regressãod e mínimos quadrados, ou seja, estamos minimizando a função do erro quadrático médio (EQM) em função dos parâmetros do modelo ($\\beta_0, \\beta_1, \\beta_2, ..., \\beta_n$). Nossa função de erro, podemos chamá-la de um nome mais geral: *função de perda* L:\n",
    "\n",
    "$$L = \\sum_{n=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2$$\n",
    "\n",
    "As formas de regularização mais populares introduzem uma \"penalização\" na função de perda devido ao aumento na complexidade do modelo - isto é, devido ao aumento do número de parâmetros (ou variáveis) no modelo.\n",
    "\n",
    "#### Regularização L1 (lasso)\n",
    "A regressão lasso introduz uma penalidade igual ao quadrado da soma dos coeficientes na função de perda:\n",
    "\n",
    "$$L_1 = \\sum_{i=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2 + \\alpha \\sum_{k=0}^{M} \\left| \\beta_k \\right|$$\n",
    "\n",
    "Em que:  \n",
    "- $\\beta_k$ são os parâmetros do modelo (atenção que $\\beta_0$ é o intercepto).\n",
    "- N é o número de observações\n",
    "- M é o número de parâmetros\n",
    "- $\\alpha$ no statsmodels é um *hiperparâmetro* do modelo, que regula a penalidade por complexidade.\n",
    "\n",
    "Dessa forma, minimizando essa função de perda, os parâmetros do modelo tendem a ter valor absoluto menor, e caso tragam mais complexidade que explicação da variância, são \"zerados\", o que significa que a variável correspondente fica é eliminada do modelo.\n",
    "\n",
    "#### Regularização L2 (ridge)\n",
    "Outra forma de regularização é a chamada regularização *ridge*, que minimiza a seguinte perda:\n",
    "\n",
    "$$L_2 = \\sum_{i=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2 + \\alpha \\sum_{k=0}^{M} \\left| \\beta_k \\right|^2$$\n",
    "\n",
    "Em que:  \n",
    "- $\\beta_k$ são os parâmetros do modelo (atenção que $\\beta_0$ é o intercepto).\n",
    "- N é o número de observações\n",
    "- M é o número de parâmetros\n",
    "- $\\alpha$ no statsmodels é um *hiperparâmetro* do modelo, que regula a penalidade por complexidade.\n",
    "\n",
    "Essa regularização é semelhante ao *lasso*, porém a penalização é no valor absoluto dos parâmetros. Diferente do lasso, não costuma \"zerar\" os parâmetros das variáveis menos relevantes, somente reduzir os coeficientes.\n",
    "\n",
    "#### *Elastic net*\n",
    "Uma forma bem popular de regularização de regressão é o *elastic net*, que consiste na mistura dos dois otimizando a seguinte função de perda:\n",
    "\n",
    "$$L_E = \\sum_{i=1}^{N} \\left( y_i - \\hat{y_i} \\right)^2 \n",
    "    + \\alpha \\left( L1_{wt} \\sum_{k=0}^{M} \\left| \\beta_k \\right|\n",
    "                    + (1-L1_{wt}) \\sum_{k=0}^{M} \\left( \\beta_k \\right)^2\n",
    "             \\right)$$\n",
    "\n",
    "com:  \n",
    "- N é o número de observações e M o número de parâmetros\n",
    "- $\\alpha$ sendo o hiperparâmetro que dá importância à penalização  \n",
    "- $L1_{wt}$ sendo um número entre 0 e 1 \n",
    "    - quando vale 1, equivale regulaziração L1 - lasso\n",
    "    - quando 0 equivale a L2 - ridge\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos testar\n",
    "\n",
    "Vamos usar o Lasso, pois é uma forma interessante de fazer seleção de variáveis no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>tip</td>       <th>  R-squared:         </th> <td>   0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Aug 2021</td> <th>  Prob (F-statistic):</th> <td>1.62e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:56:56</td>     <th>  Log-Likelihood:    </th> <td> -372.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   244</td>      <th>  AIC:               </th> <td>   763.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   236</td>      <th>  BIC:               </th> <td>   795.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -0.0943</td> <td>    0.553</td> <td>   -0.171</td> <td> 0.865</td> <td>   -1.183</td> <td>    0.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.2]</th>     <td>   -0.3591</td> <td>    0.197</td> <td>   -1.819</td> <td> 0.070</td> <td>   -0.748</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.3]</th>     <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.4]</th>     <td>    0.4563</td> <td>    0.256</td> <td>    1.782</td> <td> 0.076</td> <td>   -0.048</td> <td>    0.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.5]</th>     <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(size)[T.6]</th>     <td>    1.3854</td> <td>    0.610</td> <td>    2.270</td> <td> 0.024</td> <td>    0.183</td> <td>    2.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>smoker[T.No]</th>     <td>   -0.0929</td> <td>    0.156</td> <td>   -0.596</td> <td> 0.552</td> <td>   -0.400</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time[T.Dinner]</th>   <td>    0.0376</td> <td>    0.185</td> <td>    0.203</td> <td> 0.839</td> <td>   -0.326</td> <td>    0.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day[T.Fri]</th>       <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day[T.Sat]</th>       <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>day[T.Sun]</th>       <td>    0.1234</td> <td>    0.178</td> <td>    0.692</td> <td> 0.490</td> <td>   -0.228</td> <td>    0.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(net_bill)</th> <td>    1.1883</td> <td>    0.178</td> <td>    6.693</td> <td> 0.000</td> <td>    0.839</td> <td>    1.538</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>72.687</td> <th>  Durbin-Watson:     </th> <td>   2.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 219.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.276</td> <th>  Prob(JB):          </th> <td>2.58e-48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.879</td> <th>  Cond. No.          </th> <td>    67.4</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    tip   R-squared:                       0.348\n",
       "Model:                            OLS   Adj. R-squared:                  0.328\n",
       "Method:                 Least Squares   F-statistic:                     15.72\n",
       "Date:                Wed, 18 Aug 2021   Prob (F-statistic):           1.62e-18\n",
       "Time:                        16:56:56   Log-Likelihood:                -372.83\n",
       "No. Observations:                 244   AIC:                             763.7\n",
       "Df Residuals:                     236   BIC:                             795.1\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -0.0943      0.553     -0.171      0.865      -1.183       0.995\n",
       "C(size)[T.2]        -0.3591      0.197     -1.819      0.070      -0.748       0.030\n",
       "C(size)[T.3]              0          0        nan        nan           0           0\n",
       "C(size)[T.4]         0.4563      0.256      1.782      0.076      -0.048       0.961\n",
       "C(size)[T.5]              0          0        nan        nan           0           0\n",
       "C(size)[T.6]         1.3854      0.610      2.270      0.024       0.183       2.588\n",
       "smoker[T.No]        -0.0929      0.156     -0.596      0.552      -0.400       0.214\n",
       "time[T.Dinner]       0.0376      0.185      0.203      0.839      -0.326       0.401\n",
       "day[T.Fri]                0          0        nan        nan           0           0\n",
       "day[T.Sat]                0          0        nan        nan           0           0\n",
       "day[T.Sun]           0.1234      0.178      0.692      0.490      -0.228       0.475\n",
       "np.log(net_bill)     1.1883      0.178      6.693      0.000       0.839       1.538\n",
       "==============================================================================\n",
       "Omnibus:                       72.687   Durbin-Watson:                   2.002\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              219.153\n",
       "Skew:                           1.276   Prob(JB):                     2.58e-48\n",
       "Kurtosis:                       6.879   Cond. No.                         67.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularization\n",
    "modelo = 'tip ~ C(size) + np.log(net_bill) + smoker + time + day'\n",
    "md = smf.ols(modelo, data = tips)\n",
    "reg = md.fit_regularized(method = 'elastic_net' \n",
    "                         , refit = True\n",
    "                         , L1_wt = 1\n",
    "                         , alpha = 0.01)\n",
    "\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    See https://en.wikipedia.org/wiki/Stepwise_regression for the details\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            print(included+[new_column])\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        print(included)\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stepwise_selection(X, y)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stepwise = sm.OLS(y, sm.add_constant(pd.DataFrame(X[variaveis]))).fit()\n",
    "reg_stepwise.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Best subsets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}\n",
    "\n",
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could take quite awhile to complete...\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "models_best = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,8):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}\n",
    "\n",
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = getBest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models.sort_values('RSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "mu = 0\n",
    "\n",
    "sigma = 1\n",
    "x = np.linspace(-5, 5, 500)\n",
    "plt.plot(x, stats.norm.pdf(x, 0, 1))\n",
    "\n",
    "xinf = np.linspace(-5, stats.norm.ppf(.025, 0, 1), 500)\n",
    "plt.fill_between(xinf, stats.norm.pdf(xinf, 0, 1), color = 'orange')\n",
    "\n",
    "xsup = np.linspace(stats.norm.ppf(.975, 0, 1), 5 , 500)\n",
    "plt.fill_between(xsup, stats.norm.pdf(xsup, 0, 1), color = 'orange')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xinf = np.linspace(-5, stats.norm.ppf(.025, 0, 1), 500)\n",
    "plt.fill_between(xinf, stats.norm.pdf(xinf, 0, 1))\n",
    "\n",
    "xsup = np.linspace(stats.norm.ppf(.975, 0, 1), 5 , 500)\n",
    "plt.fill_between(xsup, stats.norm.pdf(xsup, 0, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "from patsy import balanced\n",
    "from patsy import dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patsy.dmatrix(\"C(a, Diff)\", balanced(a=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced(a=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "from patsy import demo_data\n",
    "\n",
    "data = demo_data(\"a\", nlevels=3)\n",
    "l = [\"a3\", \"a2\", \"a1\"]\n",
    "\n",
    "dmatrix(\"C(a, levels=l)\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = [[0, 0], [0, 1], [1, 1]]\n",
    "\n",
    "dmatrix(\"C(a, ordinal)\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
